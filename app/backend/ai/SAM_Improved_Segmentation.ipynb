{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb96e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2751bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SAM 3 from Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "\n",
    "if not os.path.exists(SAM3_PATH):\n",
    "    print(\"Cloning SAM 3...\")\n",
    "    !git clone https://github.com/facebookresearch/sam3.git \"{SAM3_PATH}\"\n",
    "\n",
    "%cd \"{SAM3_PATH}\"\n",
    "!pip install -e .\n",
    "%cd /content\n",
    "\n",
    "# Install dependencies - decord needs special handling\n",
    "!pip install -q pillow-heif triton ultralytics\n",
    "!pip install -q decord\n",
    "# If decord fails, try av as fallback\n",
    "try:\n",
    "    import decord\n",
    "    print(\"‚úì decord installed\")\n",
    "except:\n",
    "    print(\"decord failed, installing av as fallback...\")\n",
    "    !pip install -q av\n",
    "\n",
    "!pip install -q ultralytics\n",
    "print(\"‚úì ultralytics installed\")\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports i setup\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "import pillow_heif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pillow_heif.register_heif_opener()\n",
    "\n",
    "# Add SAM3 to path\n",
    "SAM3_PATH = \"/content/drive/MyDrive/sam3\"\n",
    "if SAM3_PATH not in sys.path:\n",
    "    sys.path.insert(0, SAM3_PATH)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face login (required for SAM 3)\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM 3 model\n",
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "bpe_path = f\"{SAM3_PATH}/sam3/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "\n",
    "print(\"Loading SAM 3 model...\")\n",
    "model = build_sam3_image_model(bpe_path=bpe_path, device=device)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.15\n",
    "processor = Sam3Processor(model, confidence_threshold=CONFIDENCE_THRESHOLD)\n",
    "print(f\"‚úì SAM 3 loaded (threshold: {CONFIDENCE_THRESHOLD})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KONFIGURACIJA\n",
    "# ============================================================\n",
    "\n",
    "# Input/Output paths\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/TRAIN\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/segmented_output_improved\"\n",
    "\n",
    "# YOLO weights for facade detection\n",
    "YOLO_WEIGHTS = \"/content/drive/MyDrive/best.pt\"\n",
    "\n",
    "# Temporary folder for facade crops (will be created automatically)\n",
    "FACADE_DIR = \"/content/drive/MyDrive/segmented_output_improved/facade_crops\"\n",
    "\n",
    "# Component prompts - vi≈°e varijacija = bolja detekcija\n",
    "COMPONENT_PROMPTS = {\n",
    "    \"seal\": [\n",
    "        \"seal\", \"rubber seal\", \"black rubber seal\", \"gasket\",\n",
    "        \"rubber gasket\", \"weatherstrip\", \"window gasket\",\n",
    "        \"black rubber strip\", \"rubber edging\", \"edge seal\",\n",
    "        \"seal around window\", \"rubber seal around glass\"\n",
    "    ],\n",
    "    \"tin\": [\n",
    "        \"tin\", \"metal tin\", \"metal sheet\", \"metal casing\",\n",
    "        \"aluminum panel\", \"metal panel\", \"sheet metal\"\n",
    "    ],\n",
    "    \"screw\": [\n",
    "        \"screw\", \"small screw\", \"screw head\", \"fastener\",\n",
    "        \"bolt\", \"metal screw\", \"fixing screw\"\n",
    "    ],\n",
    "    \"hole\": [\n",
    "        \"hole\", \"circular hole\", \"opening\", \"perforation\",\n",
    "        \"vent hole\", \"round hole\", \"drill hole\"\n",
    "    ],\n",
    "    \"glass\": [\n",
    "        \"glass\", \"window glass\", \"transparent pane\",\n",
    "        \"glass panel\", \"window pane\", \"clear glass\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Boje za vizualizaciju\n",
    "COMPONENT_COLORS = {\n",
    "    \"seal\": (0, 0, 255),      # Plava\n",
    "    \"tin\": (0, 255, 0),       # Zelena\n",
    "    \"screw\": (255, 0, 0),     # Crvena\n",
    "    \"hole\": (255, 255, 0),    # ≈Ωuta\n",
    "    \"glass\": (255, 0, 255)    # Magenta\n",
    "}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(FACADE_DIR, exist_ok=True)\n",
    "print(f\"‚úì Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"‚úì Facade crops dir: {FACADE_DIR}\")\n",
    "print(f\"‚úì Components: {list(COMPONENT_PROMPTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e4287",
   "metadata": {},
   "source": [
    "## YOLO Facade Detection (Built-in)\n",
    "This section detects and crops facades from raw images - no need to run separate YOLO notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# YOLO FACADE DETECTION\n",
    "# Detects facades in raw images and saves crops\n",
    "# ============================================================\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def detect_and_crop_facades(source_dir, output_dir, yolo_weights, confidence=0.25):\n",
    "    \"\"\"\n",
    "    Run YOLO to detect facades and save cropped regions.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Path to TRAIN folder with positive/negative subfolders\n",
    "        output_dir: Where to save facade crops (maintains folder structure)\n",
    "        yolo_weights: Path to YOLO weights (best.pt)\n",
    "        confidence: Minimum confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of original image path -> cropped facade path\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"YOLO FACADE DETECTION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load YOLO model\n",
    "    if not os.path.exists(yolo_weights):\n",
    "        print(f\"ERROR: YOLO weights not found: {yolo_weights}\")\n",
    "        return {}\n",
    "    \n",
    "    model = YOLO(yolo_weights)\n",
    "    print(f\"‚úì YOLO model loaded: {yolo_weights}\")\n",
    "    print(f\"  Classes: {model.names}\")\n",
    "    \n",
    "    # Facade class detection\n",
    "    facade_aliases = {\"facade\", \"fascade\", \"facade_element\", \"facadeelement\"}\n",
    "    facade_ids = []\n",
    "    if model.names:\n",
    "        for cls_id, name in model.names.items():\n",
    "            if str(name).lower() in facade_aliases:\n",
    "                facade_ids.append(int(cls_id))\n",
    "        # Single-class model = use that class\n",
    "        if not facade_ids and len(model.names) == 1:\n",
    "            facade_ids = [int(list(model.names.keys())[0])]\n",
    "    \n",
    "    print(f\"  Facade class IDs: {facade_ids}\")\n",
    "    \n",
    "    image_extensions = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "    crop_mapping = {}\n",
    "    \n",
    "    for folder in ['positive', 'negative']:\n",
    "        folder_path = os.path.join(source_dir, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"  Skipping {folder}/ - not found\")\n",
    "            continue\n",
    "        \n",
    "        output_folder = os.path.join(output_dir, folder)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        images = [f for f in os.listdir(folder_path) \n",
    "                  if f.lower().endswith(image_extensions) and not f.startswith('.')]\n",
    "        \n",
    "        print(f\"\\n--- {folder}/ ({len(images)} images) ---\")\n",
    "        \n",
    "        for img_file in images:\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            \n",
    "            try:\n",
    "                # Load image via PIL (supports HEIC)\n",
    "                pil_img = Image.open(img_path)\n",
    "                if pil_img.mode != 'RGB':\n",
    "                    pil_img = pil_img.convert('RGB')\n",
    "                img_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "                h, w = img_bgr.shape[:2]\n",
    "                \n",
    "                # Run YOLO\n",
    "                results = model(img_bgr, verbose=False)\n",
    "                \n",
    "                # Find best facade detection\n",
    "                best_box = None\n",
    "                best_conf = -1.0\n",
    "                best_cls = None\n",
    "                \n",
    "                for r in results:\n",
    "                    boxes = getattr(r, 'boxes', None)\n",
    "                    if boxes is None:\n",
    "                        continue\n",
    "                    \n",
    "                    for box in boxes:\n",
    "                        conf = float(box.conf[0])\n",
    "                        cls_id = int(box.cls[0])\n",
    "                        \n",
    "                        if facade_ids and cls_id not in facade_ids:\n",
    "                            continue\n",
    "                        \n",
    "                        if conf >= confidence and conf > best_conf:\n",
    "                            best_conf = conf\n",
    "                            best_box = box\n",
    "                            best_cls = cls_id\n",
    "                \n",
    "                if best_box is None:\n",
    "                    print(f\"  {img_file}: No facade detected\")\n",
    "                    continue\n",
    "                \n",
    "                # Crop facade\n",
    "                x1, y1, x2, y2 = best_box.xyxy[0].cpu().numpy()\n",
    "                x1, y1, x2, y2 = int(max(0, x1)), int(max(0, y1)), int(min(w, x2)), int(min(h, y2))\n",
    "                \n",
    "                crop = img_bgr[y1:y2, x1:x2]\n",
    "                if crop.size == 0:\n",
    "                    print(f\"  {img_file}: Empty crop\")\n",
    "                    continue\n",
    "                \n",
    "                # Save crop\n",
    "                base_name = os.path.splitext(img_file)[0].replace(\" \", \"_\")\n",
    "                save_name = f\"{base_name}_facade.jpg\"\n",
    "                save_path = os.path.join(output_folder, save_name)\n",
    "                \n",
    "                cv2.imwrite(save_path, crop)\n",
    "                crop_mapping[img_path] = save_path\n",
    "                print(f\"  {img_file}: ‚úì facade (conf={best_conf:.2f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  {img_file}: Error - {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Detected {len(crop_mapping)} facades\")\n",
    "    print(f\"‚úì Saved to: {output_dir}\")\n",
    "    \n",
    "    return crop_mapping\n",
    "\n",
    "\n",
    "# Run YOLO facade detection\n",
    "print(\"Running YOLO facade detection on TRAIN images...\")\n",
    "facade_crops = detect_and_crop_facades(\n",
    "    source_dir=DRIVE_PATH,\n",
    "    output_dir=FACADE_DIR,\n",
    "    yolo_weights=YOLO_WEIGHTS,\n",
    "    confidence=0.25\n",
    ")\n",
    "print(f\"\\n‚úÖ YOLO facade detection complete! {len(facade_crops)} facades ready for SAM segmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cebfd",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28417016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CORE FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load image (HEIC, JPG, PNG supported)\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def segment_with_text_prompt(pil_image, text_prompt):\n",
    "    \"\"\"Segment using SAM 3 text prompt\"\"\"\n",
    "    try:\n",
    "        inference_state = processor.set_image(pil_image)\n",
    "        output = processor.set_text_prompt(\n",
    "            state=inference_state,\n",
    "            prompt=text_prompt\n",
    "        )\n",
    "        \n",
    "        masks = output.get(\"masks\", None)\n",
    "        boxes = output.get(\"boxes\", None)\n",
    "        scores = output.get(\"scores\", None)\n",
    "        \n",
    "        if masks is not None and len(masks) > 0:\n",
    "            return masks, boxes, scores\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def segment_with_multiple_prompts(pil_image, prompts_list, min_score=0.1):\n",
    "    \"\"\"Try multiple prompts and combine results\"\"\"\n",
    "    all_masks = []\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_prompts = []\n",
    "    \n",
    "    for prompt in prompts_list:\n",
    "        masks, boxes, scores = segment_with_text_prompt(pil_image, prompt)\n",
    "        \n",
    "        if masks is not None and len(masks) > 0:\n",
    "            if scores is not None:\n",
    "                for i in range(len(masks)):\n",
    "                    score = scores[i].item() if hasattr(scores[i], 'item') else float(scores[i])\n",
    "                    if score >= min_score:\n",
    "                        all_masks.append(masks[i])\n",
    "                        all_boxes.append(boxes[i] if boxes is not None else None)\n",
    "                        all_scores.append(score)\n",
    "                        all_prompts.append(prompt)\n",
    "            else:\n",
    "                for i in range(len(masks)):\n",
    "                    all_masks.append(masks[i])\n",
    "                    all_boxes.append(boxes[i] if boxes is not None else None)\n",
    "                    all_scores.append(1.0)\n",
    "                    all_prompts.append(prompt)\n",
    "    \n",
    "    return all_masks, all_boxes, all_scores, all_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e9da9",
   "metadata": {},
   "source": [
    "## Pixel-Level Mask Functions (NO bounding box!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PIXEL-LEVEL MASK FUNCTIONS\n",
    "# Ove funkcije ekstrahiraju SAMO piksele unutar maske!\n",
    "# ============================================================\n",
    "\n",
    "def extract_masked_region(image_np, mask, background_color=(0, 0, 0)):\n",
    "    \"\"\"\n",
    "    Ekstrahira SAMO piksele unutar maske.\n",
    "    Okolina postaje crna (ili zadana boja).\n",
    "    \n",
    "    Returns:\n",
    "        masked_image: Slika gdje su samo pikseli unutar maske vidljivi\n",
    "        mask_bool: Boolean maska\n",
    "    \"\"\"\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "    \n",
    "    mask_bool = mask.astype(bool)\n",
    "    if mask_bool.ndim > 2:\n",
    "        mask_bool = mask_bool.squeeze()\n",
    "    \n",
    "    # Stvori praznu sliku (crna pozadina)\n",
    "    masked_image = np.full_like(image_np, background_color)\n",
    "    \n",
    "    # Kopiraj SAMO piksele unutar maske\n",
    "    masked_image[mask_bool] = image_np[mask_bool]\n",
    "    \n",
    "    return masked_image, mask_bool\n",
    "\n",
    "\n",
    "def extract_masked_region_rgba(image_np, mask):\n",
    "    \"\"\"\n",
    "    Ekstrahira regiju s TRANSPARENTNOM pozadinom (RGBA).\n",
    "    Savr≈°eno za overlay bez okoline.\n",
    "    \"\"\"\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "    \n",
    "    mask_bool = mask.astype(bool)\n",
    "    if mask_bool.ndim > 2:\n",
    "        mask_bool = mask_bool.squeeze()\n",
    "    \n",
    "    h, w = image_np.shape[:2]\n",
    "    rgba = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "    rgba[:, :, :3] = image_np\n",
    "    rgba[:, :, 3] = (mask_bool * 255).astype(np.uint8)\n",
    "    \n",
    "    return rgba, mask_bool\n",
    "\n",
    "\n",
    "def get_tight_crop_with_mask(image_np, mask, padding=10):\n",
    "    \"\"\"\n",
    "    Tight crop oko maske, ALI pikseli izvan maske su crni.\n",
    "    \n",
    "    Returns:\n",
    "        masked_crop: Cropped slika s maskom primijenjenom\n",
    "        cropped_mask: Cropped boolean maska\n",
    "    \"\"\"\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "    \n",
    "    mask_bool = mask.astype(bool)\n",
    "    if mask_bool.ndim > 2:\n",
    "        mask_bool = mask_bool.squeeze()\n",
    "    \n",
    "    # Naƒëi bounding box maske\n",
    "    rows = np.any(mask_bool, axis=1)\n",
    "    cols = np.any(mask_bool, axis=0)\n",
    "    \n",
    "    if not rows.any() or not cols.any():\n",
    "        return None, None\n",
    "    \n",
    "    y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "    x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    # Dodaj padding\n",
    "    h, w = image_np.shape[:2]\n",
    "    y_min = max(0, y_min - padding)\n",
    "    y_max = min(h, y_max + padding)\n",
    "    x_min = max(0, x_min - padding)\n",
    "    x_max = min(w, x_max + padding)\n",
    "    \n",
    "    # Crop\n",
    "    cropped_image = image_np[y_min:y_max, x_min:x_max].copy()\n",
    "    cropped_mask = mask_bool[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    # Primijeni masku - pikseli izvan su crni\n",
    "    masked_crop = cropped_image.copy()\n",
    "    masked_crop[~cropped_mask] = 0\n",
    "    \n",
    "    return masked_crop, cropped_mask\n",
    "\n",
    "\n",
    "print(\"‚úì Pixel-level mask functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffdcaf5",
   "metadata": {},
   "source": [
    "## Mask Processing & Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb68c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MASK PROCESSING & REFINEMENT\n",
    "# ============================================================\n",
    "\n",
    "def refine_mask_morphology(mask, kernel_size=5, iterations=2):\n",
    "    \"\"\"\n",
    "    Pobolj≈°aj masku morfolo≈°kim operacijama.\n",
    "    - Closing: zatvara male rupe\n",
    "    - Opening: uklanja ≈°um\n",
    "    \"\"\"\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.cpu().numpy()\n",
    "    \n",
    "    mask_uint8 = (mask.astype(bool) * 255).astype(np.uint8)\n",
    "    if mask_uint8.ndim > 2:\n",
    "        mask_uint8 = mask_uint8.squeeze()\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    \n",
    "    # Closing - zatvara male rupe\n",
    "    closed = cv2.morphologyEx(mask_uint8, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
    "    \n",
    "    # Opening - uklanja ≈°um\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    return opened > 0\n",
    "\n",
    "\n",
    "def combine_overlapping_masks(masks, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Kombiniraj maske koje se preklapaju (duplikati).\n",
    "    \"\"\"\n",
    "    if len(masks) <= 1:\n",
    "        return masks\n",
    "    \n",
    "    mask_arrays = []\n",
    "    for m in masks:\n",
    "        if isinstance(m, torch.Tensor):\n",
    "            m = m.cpu().numpy()\n",
    "        if m.ndim > 2:\n",
    "            m = m.squeeze()\n",
    "        mask_arrays.append(m.astype(bool))\n",
    "    \n",
    "    combined = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, m1 in enumerate(mask_arrays):\n",
    "        if i in used:\n",
    "            continue\n",
    "        \n",
    "        current_mask = m1.copy()\n",
    "        used.add(i)\n",
    "        \n",
    "        for j, m2 in enumerate(mask_arrays):\n",
    "            if j <= i or j in used:\n",
    "                continue\n",
    "            \n",
    "            intersection = np.logical_and(current_mask, m2).sum()\n",
    "            union = np.logical_or(current_mask, m2).sum()\n",
    "            iou = intersection / union if union > 0 else 0\n",
    "            \n",
    "            if iou > iou_threshold:\n",
    "                current_mask = np.logical_or(current_mask, m2)\n",
    "                used.add(j)\n",
    "        \n",
    "        combined.append(current_mask)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "def filter_masks_by_size(masks, min_area=100, max_area_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Filtriraj maske po veliƒçini.\n",
    "    - Ukloni premale (≈°um)\n",
    "    - Ukloni prevelike (cijela slika)\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    for m in masks:\n",
    "        if isinstance(m, torch.Tensor):\n",
    "            m = m.cpu().numpy()\n",
    "        if m.ndim > 2:\n",
    "            m = m.squeeze()\n",
    "        \n",
    "        area = m.sum()\n",
    "        total = m.size\n",
    "        \n",
    "        if area >= min_area and area / total <= max_area_ratio:\n",
    "            filtered.append(m)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "print(\"‚úì Mask processing functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b705e",
   "metadata": {},
   "source": [
    "## Visualization & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299eb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION & EXPORT\n",
    "# ============================================================\n",
    "\n",
    "def create_component_overlay(image_np, all_results, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Stvori overlay s pixel maskama (ne bounding boxovima!).\n",
    "    \"\"\"\n",
    "    overlay = image_np.copy().astype(np.float32)\n",
    "    \n",
    "    for component, data in all_results.items():\n",
    "        masks = data.get('masks', [])\n",
    "        color = np.array(COMPONENT_COLORS.get(component, (128, 128, 128)))\n",
    "        \n",
    "        for mask in masks:\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "            \n",
    "            mask_bool = mask.astype(bool)\n",
    "            if mask_bool.ndim > 2:\n",
    "                mask_bool = mask_bool.squeeze()\n",
    "            \n",
    "            # Primijeni boju SAMO na piksele unutar maske\n",
    "            overlay[mask_bool] = overlay[mask_bool] * (1 - alpha) + color * alpha\n",
    "    \n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "\n",
    "def create_mask_contours(image_np, all_results, thickness=2):\n",
    "    \"\"\"\n",
    "    Nacrtaj samo konture maski (bez fill-a).\n",
    "    \"\"\"\n",
    "    result = image_np.copy()\n",
    "    \n",
    "    for component, data in all_results.items():\n",
    "        masks = data.get('masks', [])\n",
    "        scores = data.get('scores', [])\n",
    "        color = COMPONENT_COLORS.get(component, (128, 128, 128))\n",
    "        \n",
    "        for i, mask in enumerate(masks):\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "            \n",
    "            mask_bool = mask.astype(bool)\n",
    "            if mask_bool.ndim > 2:\n",
    "                mask_bool = mask_bool.squeeze()\n",
    "            \n",
    "            # Nacrtaj konturu\n",
    "            contours, _ = cv2.findContours(\n",
    "                mask_bool.astype(np.uint8),\n",
    "                cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "            cv2.drawContours(result, contours, -1, color, thickness)\n",
    "            \n",
    "            # Label\n",
    "            if len(contours) > 0:\n",
    "                M = cv2.moments(contours[0])\n",
    "                if M[\"m00\"] > 0:\n",
    "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    score = scores[i] if i < len(scores) else 0\n",
    "                    if hasattr(score, 'item'):\n",
    "                        score = score.item()\n",
    "                    label = f\"{component}:{score:.2f}\"\n",
    "                    cv2.putText(result, label, (cx-30, cy),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 2)\n",
    "                    cv2.putText(result, label, (cx-30, cy),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def save_individual_components(image_np, all_results, output_dir, base_name):\n",
    "    \"\"\"\n",
    "    Spremi svaku komponentu zasebno (bez okoline!).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved_files = []\n",
    "    \n",
    "    for component, data in all_results.items():\n",
    "        masks = data.get('masks', [])\n",
    "        scores = data.get('scores', [])\n",
    "        \n",
    "        for i, mask in enumerate(masks):\n",
    "            masked_crop, _ = get_tight_crop_with_mask(image_np, mask)\n",
    "            \n",
    "            if masked_crop is None:\n",
    "                continue\n",
    "            \n",
    "            score = scores[i] if i < len(scores) else 0.0\n",
    "            if hasattr(score, 'item'):\n",
    "                score = score.item()\n",
    "            \n",
    "            filename = f\"{base_name}_{component}_{i+1}_score{score:.2f}.png\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            cv2.imwrite(filepath, cv2.cvtColor(masked_crop, cv2.COLOR_RGB2BGR))\n",
    "            saved_files.append(filepath)\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "\n",
    "def save_results_json(all_results, output_path, image_name, image_size):\n",
    "    \"\"\"\n",
    "    Spremi JSON s informacijama o maskama.\n",
    "    \"\"\"\n",
    "    json_data = {\n",
    "        'image': image_name,\n",
    "        'size': list(image_size),\n",
    "        'components': {}\n",
    "    }\n",
    "    \n",
    "    for component, data in all_results.items():\n",
    "        masks = data.get('masks', [])\n",
    "        scores = data.get('scores', [])\n",
    "        \n",
    "        component_info = []\n",
    "        for i, mask in enumerate(masks):\n",
    "            mask_bool = mask if isinstance(mask, np.ndarray) else mask.cpu().numpy()\n",
    "            if mask_bool.ndim > 2:\n",
    "                mask_bool = mask_bool.squeeze()\n",
    "            \n",
    "            area = int(mask_bool.sum())\n",
    "            coverage = float(area / mask_bool.size)\n",
    "            \n",
    "            # Bounding box\n",
    "            rows = np.any(mask_bool, axis=1)\n",
    "            cols = np.any(mask_bool, axis=0)\n",
    "            if rows.any() and cols.any():\n",
    "                y_min, y_max = int(np.where(rows)[0][0]), int(np.where(rows)[0][-1])\n",
    "                x_min, x_max = int(np.where(cols)[0][0]), int(np.where(cols)[0][-1])\n",
    "                bbox = [x_min, y_min, x_max, y_max]\n",
    "            else:\n",
    "                bbox = None\n",
    "            \n",
    "            score = scores[i] if i < len(scores) else 1.0\n",
    "            if hasattr(score, 'item'):\n",
    "                score = score.item()\n",
    "            \n",
    "            component_info.append({\n",
    "                'index': i,\n",
    "                'area_pixels': area,\n",
    "                'coverage_percent': round(coverage * 100, 2),\n",
    "                'bbox': bbox,\n",
    "                'score': round(float(score), 3)\n",
    "            })\n",
    "        \n",
    "        json_data['components'][component] = component_info\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "\n",
    "\n",
    "print(\"‚úì Visualization & export functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3f503",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MAIN PROCESSING FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def process_image(image_path, output_dir, save_components=True):\n",
    "    \"\"\"\n",
    "    Procesiraj jednu sliku:\n",
    "    1. Segmentiraj sve komponente\n",
    "    2. Refiniraj maske (morfologija + dedup)\n",
    "    3. Spremi overlay, komponente, JSON\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {os.path.basename(image_path)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load\n",
    "    pil_image = load_image(image_path)\n",
    "    if pil_image is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Resize ako je preveliko\n",
    "    max_dim = 1536\n",
    "    w, h = pil_image.size\n",
    "    if max(h, w) > max_dim:\n",
    "        scale = max_dim / max(h, w)\n",
    "        pil_image = pil_image.resize((int(w*scale), int(h*scale)), Image.LANCZOS)\n",
    "        print(f\"  Resized: {w}x{h} ‚Üí {pil_image.size}\")\n",
    "    \n",
    "    image_np = np.array(pil_image)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0].replace(\" \", \"_\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_results = {}\n",
    "    total_detections = 0\n",
    "    \n",
    "    # Segment svaku komponentu\n",
    "    for component, prompts in COMPONENT_PROMPTS.items():\n",
    "        print(f\"  [{component}] \", end=\"\")\n",
    "        \n",
    "        masks, boxes, scores, used_prompts = segment_with_multiple_prompts(\n",
    "            pil_image, prompts, min_score=0.1\n",
    "        )\n",
    "        \n",
    "        if masks and len(masks) > 0:\n",
    "            # 1. Refiniraj morfologijom\n",
    "            refined_masks = [refine_mask_morphology(m, kernel_size=3) for m in masks]\n",
    "            \n",
    "            # 2. Filtriraj po veliƒçini\n",
    "            filtered_masks = filter_masks_by_size(refined_masks, min_area=100)\n",
    "            \n",
    "            # 3. Kombiniraj preklapajuƒáe\n",
    "            combined_masks = combine_overlapping_masks(filtered_masks, iou_threshold=0.3)\n",
    "            \n",
    "            print(f\"‚úì {len(masks)} ‚Üí {len(combined_masks)} masks\")\n",
    "            total_detections += len(combined_masks)\n",
    "            \n",
    "            all_results[component] = {\n",
    "                'masks': combined_masks,\n",
    "                'scores': scores[:len(combined_masks)] if scores else [1.0] * len(combined_masks)\n",
    "            }\n",
    "        else:\n",
    "            print(f\"‚úó none\")\n",
    "    \n",
    "    print(f\"\\n  TOTAL: {total_detections} components\")\n",
    "    \n",
    "    # Save results\n",
    "    # 1. Overlay\n",
    "    overlay = create_component_overlay(image_np, all_results, alpha=0.4)\n",
    "    overlay_path = os.path.join(output_dir, f\"{base_name}_overlay.jpg\")\n",
    "    cv2.imwrite(overlay_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # 2. Contours only\n",
    "    contours_img = create_mask_contours(image_np, all_results)\n",
    "    contours_path = os.path.join(output_dir, f\"{base_name}_contours.jpg\")\n",
    "    cv2.imwrite(contours_path, cv2.cvtColor(contours_img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    # 3. Individual components\n",
    "    if save_components:\n",
    "        comp_dir = os.path.join(output_dir, \"components\", base_name)\n",
    "        saved = save_individual_components(image_np, all_results, comp_dir, base_name)\n",
    "        print(f\"  Saved {len(saved)} component crops\")\n",
    "    \n",
    "    # 4. JSON\n",
    "    json_path = os.path.join(output_dir, f\"{base_name}_masks.json\")\n",
    "    save_results_json(all_results, json_path, os.path.basename(image_path), pil_image.size)\n",
    "    \n",
    "    print(f\"  ‚úì Saved to: {output_dir}\")\n",
    "    \n",
    "    return all_results, overlay\n",
    "\n",
    "\n",
    "print(\"‚úì Main processing function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350a81a",
   "metadata": {},
   "source": [
    "## Test on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test na jednoj slici\n",
    "test_folder = FACADE_DIR + \"/positive\"  # Uses our own YOLO facade crops\n",
    "\n",
    "if os.path.exists(test_folder):\n",
    "    test_images = [f for f in os.listdir(test_folder) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if test_images:\n",
    "        test_path = os.path.join(test_folder, test_images[0])\n",
    "        output_test = os.path.join(OUTPUT_DIR, \"test\")\n",
    "        \n",
    "        results, overlay = process_image(test_path, output_test)\n",
    "        \n",
    "        # Load and resize original to match mask dimensions\n",
    "        orig_pil = load_image(test_path)\n",
    "        max_dim = 1536\n",
    "        w, h = orig_pil.size\n",
    "        if max(h, w) > max_dim:\n",
    "            scale = max_dim / max(h, w)\n",
    "            orig_pil = orig_pil.resize((int(w*scale), int(h*scale)), Image.LANCZOS)\n",
    "        orig = np.array(orig_pil)\n",
    "        \n",
    "        # Prika≈æi rezultate\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original\n",
    "        axes[0].imshow(orig)\n",
    "        axes[0].set_title(\"Original\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        axes[1].imshow(overlay)\n",
    "        axes[1].set_title(\"Overlay (pixel masks)\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Contours\n",
    "        contours = create_mask_contours(orig, results)\n",
    "        axes[2].imshow(contours)\n",
    "        axes[2].set_title(\"Contours only\")\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Prika≈æi pojedinaƒçne komponente\n",
    "        print(\"\\n=== Individual Components (no background!) ===\")\n",
    "        for comp, data in results.items():\n",
    "            if data['masks']:\n",
    "                num_masks = min(len(data['masks']), 5)\n",
    "                print(f\"\\n{comp.upper()}: {len(data['masks'])} masks\")\n",
    "                \n",
    "                fig, axes = plt.subplots(1, num_masks, figsize=(3*num_masks, 3))\n",
    "                if num_masks == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for i, mask in enumerate(data['masks'][:5]):\n",
    "                    try:\n",
    "                        crop, _ = get_tight_crop_with_mask(orig, mask)\n",
    "                        if crop is not None:\n",
    "                            axes[i].imshow(crop)\n",
    "                            score = data['scores'][i] if i < len(data['scores']) else 0\n",
    "                            axes[i].set_title(f\"Score: {score:.2f}\")\n",
    "                            axes[i].axis('off')\n",
    "                    except Exception as e:  \n",
    "                        print(f\"  Error showing {comp} #{i}: {e}\")\n",
    "                        axes[i].set_title(\"Error\")\n",
    "                        axes[i].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    else:\n",
    "        print(\"No test images found! Run YOLO facade detection first (cell above).\")\n",
    "else:\n",
    "    print(f\"Test folder not found: {test_folder}\")\n",
    "    print(\"Run YOLO facade detection first (cell above)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cffe99",
   "metadata": {},
   "source": [
    "## Process All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_folder):\n",
    "    \"\"\"Process all images in folder\"\"\"\n",
    "    extensions = ('.jpg', '.jpeg', '.png', '.heic', '.heif')\n",
    "    images = [f for f in os.listdir(folder_path)\n",
    "              if f.lower().endswith(extensions) and not f.startswith('.')]\n",
    "    \n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"Processing {len(images)} images from {folder_path}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    \n",
    "    for i, img_file in enumerate(images):\n",
    "        print(f\"\\n[{i+1}/{len(images)}]\", end=\"\")\n",
    "        \n",
    "        input_path = os.path.join(folder_path, img_file)\n",
    "        \n",
    "        try:\n",
    "            process_image(input_path, output_folder, save_components=True)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"Done! Results: {output_folder}\")\n",
    "\n",
    "\n",
    "# Process positive folder (using our YOLO facade crops)\n",
    "positive_path = FACADE_DIR + \"/positive\"\n",
    "if os.path.exists(positive_path):\n",
    "    process_folder(positive_path, os.path.join(OUTPUT_DIR, \"positive\"))\n",
    "else:\n",
    "    print(f\"Positive folder not found: {positive_path}\")\n",
    "    print(\"Run YOLO facade detection cell first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process negative folder (using our YOLO facade crops)\n",
    "negative_path = FACADE_DIR + \"/negative\"\n",
    "if os.path.exists(negative_path):\n",
    "    process_folder(negative_path, os.path.join(OUTPUT_DIR, \"negative\"))\n",
    "else:\n",
    "    print(f\"Negative folder not found: {negative_path}\")\n",
    "    print(\"Run YOLO facade detection cell first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdac74d",
   "metadata": {},
   "source": [
    "## Done! üéâ\n",
    "\n",
    "This notebook is **fully independent** - it includes:\n",
    "1. **YOLO facade detection** - crops facades from raw TRAIN images\n",
    "2. **SAM3 segmentation** - extracts pixel-level masks for all components\n",
    "\n",
    "Results saved to: `/content/drive/MyDrive/segmented_output_improved/`\n",
    "\n",
    "**Output structure:**\n",
    "```\n",
    "segmented_output_improved/\n",
    "‚îú‚îÄ‚îÄ facade_crops/           # YOLO facade crops (intermediate)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ positive/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ negative/\n",
    "‚îú‚îÄ‚îÄ positive/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ IMG_xxx_overlay.jpg      # Vizualizacija s maskama\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ IMG_xxx_contours.jpg     # Samo konture\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ IMG_xxx_masks.json       # Metadata (area, bbox, coverage%)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ components/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ IMG_xxx/\n",
    "‚îÇ           ‚îú‚îÄ‚îÄ IMG_xxx_tin_1_score0.85.png    # Izolirane komponente\n",
    "‚îÇ           ‚îú‚îÄ‚îÄ IMG_xxx_glass_1_score0.92.png\n",
    "‚îÇ           ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ negative/\n",
    "    ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "**No need to run YOLO_SAM_Facade_Colab.ipynb separately!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
